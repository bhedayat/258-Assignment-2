{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold for Level 1 is 0.36\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "Threshold for Level 2 is 0.69\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50,bootstrap= False, criterion = 'gini', max_depth =  3)\n",
    "\n",
    "Threshold for Level 3 \n",
    "\n",
    "['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NL', 'PT', 'other']\n",
    "[0.013,0.051,0.025,0.078,0.168,0.0761,0.10,0.023,0.002, 0.434]\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "params = {'n_estimators': 100, 'learning_rate': 0.1, 'verbose':1, 'random_state':42} \n",
    "\n",
    "clf =  OneVsRestClassifier(GradientBoostingClassifier(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, date \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load in Data\n",
    "train_users_path = '../../Data/train_users_2.csv'\n",
    "train_users = pd.read_csv(train_users_path)\n",
    "\n",
    "sessions_path = '../../Data/sessions.csv'\n",
    "sessions = pd.read_csv(sessions_path)\n",
    "\n",
    "test_users_path = '../../Data/test_users.csv'\n",
    "test_users = pd.read_csv(test_users_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "final_train_users = train_users[train_users['id'].drop_duplicates().isin(sessions['user_id'].drop_duplicates())]\n",
    "#final_train_users = final_train_users.reset_index()\n",
    "actions = sessions['action'].dropna().drop_duplicates()\n",
    "\n",
    "def action_bool(action):\n",
    "    user_action = sessions[sessions['action'] == action]\n",
    "    performed = final_train_users['id'].isin(user_action['user_id'])\n",
    "    colname = 'b_' + action\n",
    "    final_train_users[colname] = performed\n",
    "\n",
    "    \n",
    "for action in actions:\n",
    "    action_bool(action)\n",
    "feats = map(lambda x: 'b_' + x,actions)\n",
    "X = final_train_users[feats + ['country_destination']]\n",
    "Xsh = shuffle(X,random_state = 42).reset_index()\n",
    "Xsh = Xsh.as_matrix()[:,1:]\t\n",
    "ntrain = len(Xsh)\n",
    "\n",
    "Xtrain1 = Xsh[:ntrain,:-1]\n",
    "ytrain1 = np.ravel(Xsh[:ntrain,-1:] != 'NDF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73815, 359)\n",
      "(73815,)\n"
     ]
    }
   ],
   "source": [
    "print Xtrain1.shape\n",
    "print ytrain1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "final_test_users = test_users[test_users['id'].drop_duplicates().isin(sessions['user_id'].drop_duplicates())]\n",
    "#final_test_users = final_test_users.reset_index()\n",
    "\n",
    "def action_bool(action):\n",
    "    user_action = sessions[sessions['action'] == action]\n",
    "    performed = final_test_users['id'].isin(user_action['user_id'])\n",
    "    colname = 'b_' + action\n",
    "    final_test_users[colname] = performed\n",
    "\n",
    "    \n",
    "for action in actions:\n",
    "    action_bool(action)\n",
    "feats = map(lambda x: 'b_' + x,actions)\n",
    "X = final_test_users[feats]\n",
    "Xtest1 = X.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61668, 359)\n"
     ]
    }
   ],
   "source": [
    "print Xtest1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf1.fit(Xtrain1,ytrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred1 = np.array([True]*len(test_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.36\n",
    "tempPred = clf1.predict_proba(Xtest1)[:,1] >= thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in final_test_users.index.values:\n",
    "    pred1[i] = tempPred[j]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23887\n",
      "62096\n"
     ]
    }
   ],
   "source": [
    "print sum(pred1)\n",
    "print len(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predNDF = []\n",
    "for i in pred1:\n",
    "    if i == True:\n",
    "        predNDF.append('NDF')\n",
    "    else:\n",
    "        predNDF.append('NonNDF')\n",
    "predNDF = np.array(predNDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_users['bNDF'] = predNDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "booked_train_users = train_users[train_users['country_destination'] != 'NDF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encdemall = []\n",
    "Dall = []\n",
    "def makeFeature(column):\n",
    "    encdem = OneHotEncoder()\n",
    "\n",
    "    temp = (booked_train_users[column]).as_matrix()\n",
    "\n",
    "    D = defaultdict(int)\n",
    "    count = 1\n",
    "    for i in np.unique(temp):\n",
    "        D[i] = count\n",
    "        count += 1\n",
    "    \n",
    "\n",
    "    newX = np.zeros((temp.shape))\n",
    "    for i in range(temp.shape[0]):\n",
    "        lang = temp[i]\n",
    "        newX[i] = D[lang]\n",
    "    newX = newX[:,np.newaxis]\n",
    "    \n",
    "    newX = encdem.fit_transform(newX)\n",
    "    \n",
    "    newX = newX.toarray()\n",
    "    \n",
    "    return newX,encdem,D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:216: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88908, 109)\n"
     ]
    }
   ],
   "source": [
    "columns = ['signup_method', 'signup_flow', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "\n",
    "X1tr,encdem,D = makeFeature('gender')\n",
    "encdemall.append(encdem)\n",
    "Dall.append(D)\n",
    "for c in columns:\n",
    "    tempX,encdem,D = makeFeature(c)\n",
    "    encdemall.append(encdem)\n",
    "    Dall.append(D)\n",
    "    X1tr = np.concatenate((X1tr,tempX),axis=1)\n",
    "print X1tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def action_bool(action):\n",
    "    user_action = sessions[sessions['action'] == action]\n",
    "    performed = booked_train_users['id'].isin(user_action['user_id'])\n",
    "    colname = 'b_' + action\n",
    "    booked_train_users[colname] = performed\n",
    "\n",
    "actions = sessions['action'].dropna().drop_duplicates()\n",
    "\n",
    "for action in actions:\n",
    "    action_bool(action)\n",
    "\n",
    "col_name = ['b_' + action for action in actions]\n",
    "\n",
    "actXtr = booked_train_users[col_name].as_matrix().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88908, 359)\n"
     ]
    }
   ],
   "source": [
    "print actXtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88908, 1)\n"
     ]
    }
   ],
   "source": [
    "Xtr = (booked_train_users['language'] == 'en').as_matrix().astype(int)\n",
    "Xtr = Xtr[:,np.newaxis]\n",
    "print Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = 2000 # dummy leap year to allow input X-02-29 (leap day)\n",
    "seasons = [(0, (date(Y,  1,  1),  date(Y,  3, 20))),  #'winter'\n",
    "           (1, (date(Y,  3, 21),  date(Y,  6, 20))),  #'spring'\n",
    "           (2, (date(Y,  6, 21),  date(Y,  9, 22))),  #'summer'\n",
    "           (3, (date(Y,  9, 23),  date(Y, 12, 20))),  #'autumn'\n",
    "           (0, (date(Y, 12, 21),  date(Y, 12, 31)))]  #'winter'\n",
    "def get_season(now):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    d1 = now\n",
    "    now = datetime.strptime(d1, date_format)\n",
    "    \n",
    "    if isinstance(now, datetime):\n",
    "        now = now.date()\n",
    "    now = now.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= now <= end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88908, 4)\n"
     ]
    }
   ],
   "source": [
    "encdate = OneHotEncoder()\n",
    "a = np.array(booked_train_users['date_account_created'].apply(get_season))\n",
    "a = a[:,np.newaxis]\n",
    "dateFeattr = encdate.fit_transform(a)\n",
    "dateFeattr = dateFeattr.toarray()\n",
    "print dateFeattr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88908, 473)\n"
     ]
    }
   ],
   "source": [
    "Xtrain2 = np.concatenate((actXtr,Xtr,dateFeattr,X1tr),axis=1)\n",
    "ytrain2 = (booked_train_users['country_destination'] == 'US').as_matrix().astype(int)\n",
    "print Xtrain2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "booked_test_users = test_users[test_users['bNDF'] != 'NDF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def makeFeature(column,encdem,D):\n",
    "    temp = (booked_test_users[column]).as_matrix()\n",
    "\n",
    "    newX = np.zeros((temp.shape))\n",
    "    for i in range(temp.shape[0]):\n",
    "        lang = temp[i]\n",
    "        newX[i] = D[lang]\n",
    "    newX = newX[:,np.newaxis]\n",
    "    \n",
    "    newX = encdem.transform(newX)\n",
    "    newX = newX.toarray()\n",
    "    \n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38209, 109)\n"
     ]
    }
   ],
   "source": [
    "columns = ['signup_method', 'signup_flow', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "\n",
    "j = 0\n",
    "\n",
    "X1 = makeFeature('gender',encdemall[j],Dall[j])\n",
    "j += 1\n",
    "for c in columns:\n",
    "    encdem = encdemall[j]\n",
    "    D = Dall[j]\n",
    "    tempX = makeFeature(c,encdem,D)\n",
    "    X1 = np.concatenate((X1,tempX),axis=1)\n",
    "    j += 1\n",
    "print X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38209, 359)\n"
     ]
    }
   ],
   "source": [
    "def action_bool(action):\n",
    "    user_action = sessions[sessions['action'] == action]\n",
    "    performed = booked_test_users['id'].isin(user_action['user_id'])\n",
    "    colname = 'b_' + action\n",
    "    booked_test_users[colname] = performed\n",
    "\n",
    "actions = sessions['action'].dropna().drop_duplicates()\n",
    "\n",
    "for action in actions:\n",
    "    action_bool(action)\n",
    "\n",
    "col_name = ['b_' + action for action in actions]\n",
    "\n",
    "actX = booked_test_users[col_name].as_matrix().astype(int)\n",
    "print actX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38209, 1)\n"
     ]
    }
   ],
   "source": [
    "X = (booked_test_users['language'] == 'en').as_matrix().astype(int)\n",
    "X = X[:,np.newaxis]\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38209, 4)\n"
     ]
    }
   ],
   "source": [
    "a = np.array(booked_test_users['date_account_created'].apply(get_season))\n",
    "a = a[:,np.newaxis]\n",
    "dateFeat = encdate.transform(a)\n",
    "dateFeat = dateFeat.toarray()\n",
    "print dateFeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest2 = np.concatenate((actX,X,dateFeat,X1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38209, 473)\n",
      "(88908, 473)\n"
     ]
    }
   ],
   "source": [
    "print Xtest2.shape\n",
    "print Xtrain2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators=50,bootstrap= False, criterion = 'gini', max_depth =  3)\n",
    "\n",
    "clf2.fit(Xtrain2,ytrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predict for Level 2\n",
    "thresh = 0.69\n",
    "pred2 = clf2.predict_proba(Xtest2)[:,1] >= thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predUS = []\n",
    "for i in pred2:\n",
    "    if i == True:\n",
    "        predUS.append('US')\n",
    "    else:\n",
    "        predUS.append('NonUS')\n",
    "predUS = np.array(predUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "booked_test_users['bUS'] = predUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Users who had a booking\n",
    "train_yesPurchase = train_users[train_users['country_destination']!='NDF']\n",
    "yesPurchase_users = set(train_yesPurchase['id'])\n",
    "\n",
    "# Users who had a booking outside of US\n",
    "train_nonUS_purchase = train_yesPurchase[train_yesPurchase['country_destination'] != 'US']\n",
    "#train_nonUS_purchase = train_nonUS_purchase[train_nonUS_purchase['country_destination'] != 'other']\n",
    "train_nonUS_users = set(train_nonUS_purchase ['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_train_users = train_nonUS_purchase.copy()\n",
    "count_train_users = count_train_users[count_train_users['id'].isin(sessions['user_id'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = list(train_users.columns.values)\n",
    "categories = categories[4:len(categories)-1]\n",
    "categories.remove('age')\n",
    "categories.remove('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_train_users = count_train_users.ix[np.logical_and(count_train_users['age'] > 10, count_train_users['age'] < 80)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_bool(catName, catItem):\n",
    "    user_app = count_train_users[count_train_users[catName] == catItem]\n",
    "    performed = count_train_users['id'].isin(user_app['id'])\n",
    "    colname = str(catName) + '_' + str(catItem)\n",
    "    count_train_users[colname] = performed\n",
    "\n",
    "for category in categories:\n",
    "    items = count_train_users[category].dropna().drop_duplicates()\n",
    "    for item in items:\n",
    "        category_bool(category, item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genders = count_train_users['gender'].dropna().drop_duplicates()\n",
    "for item in genders:\n",
    "    if (item != '-unknown-'):\n",
    "        category_bool('gender', item)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Get the Date\n",
    "from datetime import datetime, date \n",
    "Y = 2000 # dummy leap year to allow input X-02-29 (leap day)\n",
    "seasons = [(0, (date(Y,  1,  1),  date(Y,  3, 20))),  #'winter'\n",
    "           (1, (date(Y,  3, 21),  date(Y,  6, 20))),  #'spring'\n",
    "           (2, (date(Y,  6, 21),  date(Y,  9, 22))),  #'summer'\n",
    "           (3, (date(Y,  9, 23),  date(Y, 12, 20))),  #'autumn'\n",
    "           (0, (date(Y, 12, 21),  date(Y, 12, 31)))]  #'winter'\n",
    "\n",
    "def get_season(now):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    d1 = now\n",
    "    now = datetime.strptime(d1, date_format)\n",
    "    \n",
    "    if isinstance(now, datetime):\n",
    "        now = now.date()\n",
    "    now = now.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= now <= end)\n",
    "\n",
    "encdate = OneHotEncoder()\n",
    "a = np.array(count_train_users['date_account_created'].apply(get_season))\n",
    "\n",
    "b = np.array([0,1,2,3])\n",
    "b = b[:,np.newaxis]\n",
    "encdate.fit(b)\n",
    "\n",
    "a = a[:,np.newaxis]\n",
    "dateFeat = encdate.transform(a)\n",
    "dateFeat = dateFeat.toarray()\n",
    "\n",
    "for i in range(len(dateFeat[0])):\n",
    "    category = 'season_' + str(i)\n",
    "    count_train_users[category] = dateFeat[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Append Month\n",
    "def get_month(now):\n",
    "    return now[5:7]\n",
    "\n",
    "encmonth = OneHotEncoder()\n",
    "a = np.array(count_train_users['date_account_created'].apply(get_month))\n",
    "a = a[:,np.newaxis]\n",
    "\n",
    "b = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "b = b[:,np.newaxis]\n",
    "encmonth.fit(b)\n",
    "\n",
    "\n",
    "dateFeat = encmonth.transform(a)\n",
    "dateFeat = dateFeat.toarray()\n",
    "\n",
    "for i in range(len(dateFeat[0])):\n",
    "    category = 'month_' + str(i)\n",
    "    count_train_users[category] = dateFeat[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Append Year\n",
    "def get_year(now):\n",
    "    return now[:4]\n",
    "\n",
    "encyear = OneHotEncoder()\n",
    "\n",
    "a = np.array(count_train_users['date_account_created'].apply(get_year))\n",
    "a = a[:,np.newaxis]\n",
    "dateFeat = encyear.fit_transform(a)\n",
    "dateFeat = dateFeat.toarray()\n",
    "\n",
    "for i in range(len(dateFeat[0])):\n",
    "    category = 'year_' + str(i)\n",
    "    count_train_users[category] = dateFeat[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Append TFA - DAC\n",
    "\n",
    "count_train_users['tfa-dac'] = count_train_users.apply(lambda x: (datetime.strptime(x['date_account_created'], '%Y-%m-%d') \\\n",
    "                     - datetime.strptime(str(x['timestamp_first_active'])[:-6], '%Y%m%d')).total_seconds()\\\n",
    "          /(60*60*24.0) \\\n",
    "          ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action_bool(action):\n",
    "    user_action = sessions[sessions['action'] == action]\n",
    "    performed = count_train_users['id'].isin(user_action['user_id'])\n",
    "    colname = 'b_' + action\n",
    "    count_train_users[colname] = performed\n",
    "\n",
    "#all actions\n",
    "actions = sessions['action'].dropna().drop_duplicates()\n",
    "for action in actions:\n",
    "    action_bool(action)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainsh = pd.concat([ count_train_users[list(count_train_users)[15:]], count_train_users['age'] ], axis=1)\n",
    "trainsh = pd.concat([ count_train_users[list(count_train_users)[15:]]], axis=1)\n",
    "\n",
    "\n",
    "trainsh = trainsh.dropna()\n",
    "trainshX = trainsh.drop(['country_destination'], axis=1)\n",
    "\n",
    "trainshY = trainsh['country_destination']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert country label y to integer format\n",
    "countryList = sorted(list(set(trainsh['country_destination'])))\n",
    "n_classes = len(countryList)\n",
    "d = defaultdict(list)\n",
    "for c in countryList:\n",
    "    d[c] = countryList.index(c)\n",
    "\n",
    "def getLabel(c):\n",
    "    return d[c]\n",
    "    \n",
    "\n",
    "newtrainshY = trainshY.apply(getLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain3 = np.array(trainshX)\n",
    "ytrain3 = newtrainshY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6258, 464)\n"
     ]
    }
   ],
   "source": [
    "print Xtrain3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_test_users = booked_test_users[booked_test_users['bUS'] == 'NonUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def category_bool(catName, catItem):\n",
    "    user_app = count_test_users[count_test_users[catName] == catItem]\n",
    "    performed = count_test_users['id'].isin(user_app['id'])\n",
    "    colname = str(catName) + '_' + str(catItem)\n",
    "    count_test_users[colname] = performed\n",
    "\n",
    "for category in categories:\n",
    "    items = count_train_users[category].dropna().drop_duplicates()\n",
    "    for item in items:\n",
    "        category_bool(category, item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "genders = count_test_users['gender'].dropna().drop_duplicates()\n",
    "for item in genders:\n",
    "    if (item != '-unknown-'):\n",
    "        category_bool('gender', item)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "a = np.array(count_test_users['date_account_created'].apply(get_season))\n",
    "a = a[:,np.newaxis]\n",
    "\n",
    "dateFeat = encdate.transform(a)\n",
    "dateFeat = dateFeat.toarray()\n",
    "\n",
    "for i in range(len(dateFeat[0])):\n",
    "    category = 'season_' + str(i)\n",
    "    count_test_users[category] = dateFeat[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "a = np.array(count_test_users['date_account_created'].apply(get_month))\n",
    "a = a[:,np.newaxis]\n",
    "dateFeat = encmonth.transform(a)\n",
    "dateFeat = dateFeat.toarray()\n",
    "\n",
    "for i in range(len(dateFeat[0])):\n",
    "    category = 'month_' + str(i)\n",
    "    count_test_users[category] = dateFeat[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "a = np.array(count_test_users['date_account_created'].apply(get_year))\n",
    "a = a[:,np.newaxis]\n",
    "dateFeat = encyear.transform(a)\n",
    "dateFeat = dateFeat.toarray()\n",
    "\n",
    "for i in range(len(dateFeat[0])):\n",
    "    category = 'year_' + str(i)\n",
    "    count_test_users[category] = dateFeat[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "## Append TFA - DAC\n",
    "\n",
    "count_test_users['tfa-dac'] = count_test_users.apply(lambda x: (datetime.strptime(x['date_account_created'], '%Y-%m-%d') \\\n",
    "                     - datetime.strptime(str(x['timestamp_first_active'])[:-6], '%Y%m%d')).total_seconds()\\\n",
    "          /(60*60*24.0) \\\n",
    "          ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def action_bool(action):\n",
    "    user_action = sessions[sessions['action'] == action]\n",
    "    performed = count_test_users['id'].isin(user_action['user_id'])\n",
    "    colname = 'b_' + action\n",
    "    count_test_users[colname] = performed\n",
    "\n",
    "#all actions\n",
    "actions = sessions['action'].dropna().drop_duplicates()\n",
    "for action in actions:\n",
    "    action_bool(action)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = ['id'] + list(trainsh.columns.values) \n",
    "c.remove('country_destination')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testsh = pd.concat([ count_test_users[list(count_test_users)[16:]], count_test_users['age'] ], axis=1)\n",
    "\n",
    "testsh = count_test_users[c]\n",
    "Xtestsh = testsh[list(testsh)[1:]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest3 = np.array(Xtestsh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6258, 464)\n",
      "(5746, 464)\n"
     ]
    }
   ],
   "source": [
    "print Xtrain3.shape\n",
    "print Xtest3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gradient Boosting (sklearn)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "params = {'n_estimators': 100, 'learning_rate': 0.1, 'verbose':1, 'random_state':42} \n",
    "clf3 =  OneVsRestClassifier(GradientBoostingClassifier(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1855            2.43s\n",
      "         2           0.1830            3.98s\n",
      "         3           0.1801            4.48s\n",
      "         4           0.1773            4.70s\n",
      "         5           0.1755            4.60s\n",
      "         6           0.1719            4.73s\n",
      "         7           0.1709            4.68s\n",
      "         8           0.1702            4.61s\n",
      "         9           0.1685            4.42s\n",
      "        10           0.1668            4.31s\n",
      "        20           0.1568            3.76s\n",
      "        30           0.1507            3.13s\n",
      "        40           0.1433            2.63s\n",
      "        50           0.1385            2.17s\n",
      "        60           0.1344            1.72s\n",
      "        70           0.1325            1.27s\n",
      "        80           0.1286            0.83s\n",
      "        90           0.1253            0.41s\n",
      "       100           0.1238            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4105            2.17s\n",
      "         2           0.4063            2.46s\n",
      "         3           0.4026            2.66s\n",
      "         4           0.4021            2.62s\n",
      "         5           0.4013            2.57s\n",
      "         6           0.3998            2.53s\n",
      "         7           0.3987            2.50s\n",
      "         8           0.3980            2.46s\n",
      "         9           0.3967            2.47s\n",
      "        10           0.3951            2.43s\n",
      "        20           0.3856            2.52s\n",
      "        30           0.3776            2.25s\n",
      "        40           0.3706            1.92s\n",
      "        50           0.3643            1.60s\n",
      "        60           0.3601            1.28s\n",
      "        70           0.3533            0.97s\n",
      "        80           0.3493            0.65s\n",
      "        90           0.3457            0.32s\n",
      "       100           0.3429            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2774            2.65s\n",
      "         2           0.2752            2.52s\n",
      "         3           0.2737            2.86s\n",
      "         4           0.2727            2.90s\n",
      "         5           0.2710            3.09s\n",
      "         6           0.2703            2.97s\n",
      "         7           0.2697            2.86s\n",
      "         8           0.2680            3.01s\n",
      "         9           0.2677            2.89s\n",
      "        10           0.2665            2.81s\n",
      "        20           0.2564            2.89s\n",
      "        30           0.2490            2.52s\n",
      "        40           0.2438            2.19s\n",
      "        50           0.2364            1.86s\n",
      "        60           0.2329            1.45s\n",
      "        70           0.2284            1.10s\n",
      "        80           0.2246            0.74s\n",
      "        90           0.2224            0.37s\n",
      "       100           0.2199            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5636            2.72s\n",
      "         2           0.5626            2.71s\n",
      "         3           0.5618            2.77s\n",
      "         4           0.5612            2.75s\n",
      "         5           0.5602            2.72s\n",
      "         6           0.5597            2.71s\n",
      "         7           0.5588            2.70s\n",
      "         8           0.5580            2.87s\n",
      "         9           0.5571            2.80s\n",
      "        10           0.5561            2.86s\n",
      "        20           0.5487            2.47s\n",
      "        30           0.5406            2.22s\n",
      "        40           0.5349            1.88s\n",
      "        50           0.5285            1.58s\n",
      "        60           0.5229            1.26s\n",
      "        70           0.5176            0.95s\n",
      "        80           0.5145            0.63s\n",
      "        90           0.5086            0.32s\n",
      "       100           0.5047            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8933            2.86s\n",
      "         2           0.8909            3.53s\n",
      "         3           0.8885            4.26s\n",
      "         4           0.8866            3.85s\n",
      "         5           0.8846            3.72s\n",
      "         6           0.8827            3.79s\n",
      "         7           0.8806            4.04s\n",
      "         8           0.8789            3.92s\n",
      "         9           0.8774            4.03s\n",
      "        10           0.8754            4.13s\n",
      "        20           0.8625            3.80s\n",
      "        30           0.8536            3.19s\n",
      "        40           0.8477            2.47s\n",
      "        50           0.8424            1.99s\n",
      "        60           0.8370            1.57s\n",
      "        70           0.8329            1.13s\n",
      "        80           0.8274            0.75s\n",
      "        90           0.8224            0.37s\n",
      "       100           0.8170            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5819            5.84s\n",
      "         2           0.5804            5.94s\n",
      "         3           0.5787            5.86s\n",
      "         4           0.5774            5.36s\n",
      "         5           0.5762            5.10s\n",
      "         6           0.5747            4.67s\n",
      "         7           0.5721            4.69s\n",
      "         8           0.5711            4.55s\n",
      "         9           0.5698            4.32s\n",
      "        10           0.5686            4.18s\n",
      "        20           0.5574            3.48s\n",
      "        30           0.5490            2.94s\n",
      "        40           0.5424            2.46s\n",
      "        50           0.5371            2.02s\n",
      "        60           0.5315            1.62s\n",
      "        70           0.5267            1.20s\n",
      "        80           0.5213            0.79s\n",
      "        90           0.5163            0.39s\n",
      "       100           0.5124            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6660            2.96s\n",
      "         2           0.6640            2.90s\n",
      "         3           0.6626            2.98s\n",
      "         4           0.6613            3.09s\n",
      "         5           0.6606            2.87s\n",
      "         6           0.6596            2.86s\n",
      "         7           0.6580            2.95s\n",
      "         8           0.6563            3.26s\n",
      "         9           0.6545            3.45s\n",
      "        10           0.6535            3.31s\n",
      "        20           0.6437            3.11s\n",
      "        30           0.6343            2.73s\n",
      "        40           0.6281            2.31s\n",
      "        50           0.6218            1.92s\n",
      "        60           0.6162            1.50s\n",
      "        70           0.6110            1.11s\n",
      "        80           0.6066            0.73s\n",
      "        90           0.6036            0.36s\n",
      "       100           0.5991            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2710            2.51s\n",
      "         2           0.2679            2.72s\n",
      "         3           0.2664            3.59s\n",
      "         4           0.2640            3.51s\n",
      "         5           0.2616            3.37s\n",
      "         6           0.2602            3.32s\n",
      "         7           0.2597            3.45s\n",
      "         8           0.2581            3.29s\n",
      "         9           0.2570            3.28s\n",
      "        10           0.2563            3.21s\n",
      "        20           0.2446            3.01s\n",
      "        30           0.2377            2.70s\n",
      "        40           0.2312            2.28s\n",
      "        50           0.2268            1.89s\n",
      "        60           0.2220            1.52s\n",
      "        70           0.2179            1.15s\n",
      "        80           0.2147            0.76s\n",
      "        90           0.2120            0.39s\n",
      "       100           0.2093            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0848            2.63s\n",
      "         2           0.0808            2.62s\n",
      "         3           0.0782            2.87s\n",
      "         4           0.0763            3.20s\n",
      "         5           0.0752            3.29s\n",
      "         6           0.0744            3.35s\n",
      "         7           0.0733            3.18s\n",
      "         8           0.0721            3.06s\n",
      "         9           0.0695            3.03s\n",
      "        10           0.0664            3.00s\n",
      "        20           0.0562            2.68s\n",
      "        30           0.0529            2.48s\n",
      "        40           0.0499            2.16s\n",
      "        50           0.0450            1.88s\n",
      "        60           0.0430            1.53s\n",
      "        70           0.0411            1.15s\n",
      "        80           0.0392            0.77s\n",
      "        90           0.0369            0.38s\n",
      "       100           0.0357            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3567            6.34s\n",
      "         2           1.3531            6.67s\n",
      "         3           1.3499            5.77s\n",
      "         4           1.3470            5.79s\n",
      "         5           1.3445            5.80s\n",
      "         6           1.3422            5.42s\n",
      "         7           1.3395            5.27s\n",
      "         8           1.3371            5.20s\n",
      "         9           1.3352            4.96s\n",
      "        10           1.3332            4.97s\n",
      "        20           1.3163            4.07s\n",
      "        30           1.3042            3.45s\n",
      "        40           1.2949            2.80s\n",
      "        50           1.2869            2.27s\n",
      "        60           1.2808            1.72s\n",
      "        70           1.2744            1.24s\n",
      "        80           1.2688            0.80s\n",
      "        90           1.2637            0.39s\n",
      "       100           1.2582            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=42,\n",
       "              subsample=1.0, verbose=1, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(Xtrain3, ytrain3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count3 = ['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NL', 'PT', 'other'] \n",
    "thresh3 = [0.013,0.051,0.025,0.078,0.168,0.0761,0.10,0.023,0.002, 0.434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count3dict = defaultdict(list)\n",
    "for i in range(len(count3)):\n",
    "    thresh = thresh3[i]\n",
    "    temp = clf3.estimators_[i].predict_proba(Xtest3)[:,1] >= thresh\n",
    "    \n",
    "    count3dict[count3[i]] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempprob3 = clf3.predict(Xtest3)\n",
    "\n",
    "prob3 = []\n",
    "for i in tempprob3:\n",
    "    prob3.append(count3[i])\n",
    "    \n",
    "prob3 = np.array(prob3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "count_test_users['bCount'] = prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('test.txt','w')\n",
    "f.write('id,country\\n')\n",
    "\n",
    "for user in test_users['id']:\n",
    "    u = test_users[test_users['id'] == user]\n",
    "    name = u['id'].values[0]\n",
    "    \n",
    "    if u['bNDF'].values[0] == 'NDF':\n",
    "        f.write(name+','+'NDF\\n')\n",
    "    else:\n",
    "        b = booked_test_users[booked_test_users['id'] == name]\n",
    "        if b['bUS'].values[0] == 'US':\n",
    "            f.write(name+','+'US\\n')\n",
    "        else:\n",
    "            c = count_test_users[count_test_users['id'] == name]\n",
    "            cc = c['bCount'].values[0]\n",
    "            f.write(name+','+cc+'\\n')\n",
    "            \n",
    "            \n",
    "f.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
